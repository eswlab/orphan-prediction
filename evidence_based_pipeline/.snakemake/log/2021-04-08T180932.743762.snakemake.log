Building DAG of jobs...
Using shell: /usr/bin/bash
Provided cores: 2
Rules claiming more threads will be scaled down.
Job counts:
	count	jobs
	1	all
	1	mikado
	2

[Thu Apr  8 18:09:34 2021]
rule mikado:
    input: direct_inference_out/portcullis_out/3-filt/portcullis_filtered.pass.junctions.bed, direct_inference_out/gtflist.txt
    output: mikado.loci.gff3
    jobid: 7

[Thu Apr  8 18:10:34 2021]
Error in rule mikado:
    jobid: 7
    output: mikado.loci.gff3
    shell:
        
		#step 1 configure
		mikado configure --list direct_inference_out/gtflist.txt --reference reference_data/TAIR10_chr_all.fas --mode nosplit --scoring mammalian_orphan.yaml --junctions direct_inference_out/portcullis_out/3-filt/portcullis_filtered.pass.junctions.bed --seed 1234 -t 12 --minimum-cdna-length 100 mkconf.yaml
		
		#step 2 prepare
		mikado prepare --json-conf mkconf.yaml -m 100 -p 12 --seed 1234
	
		#step 3 run orfipy
		orfipy mikado_prepared.fasta --min 100 --max 100000000 --outdir orfipy_out  --bed12 orfs.bed --include-stop --start ATG

		#step 4 serialise
		mikado serialise --json-conf mkconf.yaml --orfs orfipy_out/orfs.bed -nsa  -p 12 --max-objects 1000000  --seed 1234

		#step 5 pick
		mikado pick --json-conf mkconf.yaml --procs 12 --shm --mode nosplit --seed 1234

		
        (one of the commands exited with non-zero exit code; note that snakemake uses bash strict mode!)

Shutting down, this might take some time.
Exiting because a job execution failed. Look above for error message
Complete log: /ocean/projects/mcb190119p/usingh/urmi/max_orphans/orphan-prediction/evidence_based_pipeline/.snakemake/log/2021-04-08T180932.743762.snakemake.log
